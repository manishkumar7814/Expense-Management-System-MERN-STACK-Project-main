{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd06bbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Caterer Name                         Address   \n",
      "76          Indian Caterers                   Dwarka, Delhi  \\\n",
      "79           Grand Caterers           Rajouri Garden, Delhi   \n",
      "68   Kitchen Kraft Catering                    Saket, Delhi   \n",
      "143          Royal Caterers                          Ambala   \n",
      "71         Flavors Catering                   Rohini, Delhi   \n",
      "..                      ...                             ...   \n",
      "128           Silver Spoons                         Gurgaon   \n",
      "129   Chef's Table Caterers                         Gurgaon   \n",
      "130          Zayka Caterers                          Ambala   \n",
      "131        The Green Bakers                          Ambala   \n",
      "0            Laxmi Caterers  Hiran Magri, Sector 4, Udaipur   \n",
      "\n",
      "                      Price Range                   Email Address  \n",
      "76    Rs. 300 - Rs. 800 per plate        indiancaterers@gmail.com  \n",
      "79    Rs. 100 - Rs. 300 per plate    grandcaterersindia@gmail.com  \n",
      "68    Rs. 300 - Rs. 800 per plate   info@kitchenkraftcatering.com  \n",
      "143   Rs. 300 - Rs. 800 per plate          info@royalcaterers.com  \n",
      "71    Rs. 100 - Rs. 300 per plate      flavors.catering@gmail.com  \n",
      "..                            ...                             ...  \n",
      "128       ₹800 - ₹2,000 per plate  silverspoonscaterers@gmail.com  \n",
      "129     ₹2,000 - ₹5,000 per plate     info@chefstablecaterers.com  \n",
      "130       ₹800 - ₹2,000 per plate         zaykacaterers@gmail.com  \n",
      "131       ₹500 - ₹1,500 per plate         info@thegreenbakers.com  \n",
      "0    Rs. 500 - Rs. 1000 per plate           info@laxmicaterers.in  \n",
      "\n",
      "[154 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Content-Based-Filtering\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Gather data\n",
    "events = pd.read_csv('caterings1.csv')\n",
    "#url = (r\"\")\n",
    "\n",
    "\n",
    "# Define features\n",
    "features = [ 'Caterer Name','Address','Price Range','Email Address']\n",
    "\n",
    "# Preprocess data\n",
    "events = events.drop_duplicates(subset=['Email Address']) # Remove duplicates\n",
    "events = events[features].fillna('') # Fill any missing values with empty string\n",
    "\n",
    "# Vectorize features\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(events.apply(lambda x: ' '.join(x.astype(str)), axis=1))\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "# Build the model / Training the model\n",
    "def content_based_filtering(user_events):\n",
    "    # Get user's event history\n",
    "    user_vector = vectorizer.transform([' '.join(user_events)])\n",
    "    \n",
    "    # Compute similarity scores between user's history and all events\n",
    "    similarity_scores = cosine_similarity(user_vector, vectors).flatten()\n",
    "    \n",
    "    # Get top n most similar events\n",
    "    top_indices = similarity_scores.argsort()[::-1]#[:n_recommendations]\n",
    "    \n",
    "    recommend=events.iloc[top_indices]\n",
    "    \n",
    "    # Return event recommendations\n",
    "    return recommend\n",
    "\n",
    "# Train and test the model\n",
    "user_events = [\"New Delhi\",\"300\"]\n",
    "recommendations = content_based_filtering(user_events)\n",
    "print(recommendations)\n",
    "\n",
    "\n",
    "#Integrating the frontend\n",
    "#Create a function - def input_from_frontend(para 1, 2, 3, 4):\n",
    "    #Call the function content_based_filterating\n",
    "    #Return an integer #POST\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b617210b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caterer Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>Contact Number</th>\n",
       "      <th>Email Address</th>\n",
       "      <th>Specialties</th>\n",
       "      <th>Price Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Laxmi Caterers</td>\n",
       "      <td>Hiran Magri, Sector 4, Udaipur</td>\n",
       "      <td>0294-2460202</td>\n",
       "      <td>info@laxmicaterers.in</td>\n",
       "      <td>Vegetarian, North Indian, Chinese</td>\n",
       "      <td>Rs. 500 - Rs. 1000 per plate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Panna Lal Catering</td>\n",
       "      <td>Raja Park, Jaipur</td>\n",
       "      <td>098291 20009</td>\n",
       "      <td>pannalalcaterers@gmail.com</td>\n",
       "      <td>Rajasthani, North Indian, Continental</td>\n",
       "      <td>Rs. 300 - Rs. 800 per plate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jodhpur Caterers</td>\n",
       "      <td>9th C Road, Sardarpura, Jodhpur</td>\n",
       "      <td>0291-2627181</td>\n",
       "      <td>info@jodhpurcaterers.com</td>\n",
       "      <td>Rajasthani, North Indian, Chinese</td>\n",
       "      <td>Rs. 600 - Rs. 1500 per plate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shri Marwar Caterers</td>\n",
       "      <td>2nd Floor, Om Shanti Complex, Bhupalpura, Udaipur</td>\n",
       "      <td>0294-2423634</td>\n",
       "      <td>info@shrimarwarcaterers.com</td>\n",
       "      <td>Rajasthani, North Indian, Continental</td>\n",
       "      <td>Rs. 200 - Rs. 500 per plate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sharma Caterers</td>\n",
       "      <td>Ambabari, Jaipur</td>\n",
       "      <td>098290 57993</td>\n",
       "      <td>sharmacaterers.jaipur@gmail.com</td>\n",
       "      <td>Rajasthani, North Indian, Chinese</td>\n",
       "      <td>Rs. 100 - Rs. 300 per plate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Caterer Name                                            Address  \\\n",
       "0        Laxmi Caterers                     Hiran Magri, Sector 4, Udaipur   \n",
       "1    Panna Lal Catering                                  Raja Park, Jaipur   \n",
       "2      Jodhpur Caterers                    9th C Road, Sardarpura, Jodhpur   \n",
       "3  Shri Marwar Caterers  2nd Floor, Om Shanti Complex, Bhupalpura, Udaipur   \n",
       "4       Sharma Caterers                                   Ambabari, Jaipur   \n",
       "\n",
       "  Contact Number                    Email Address  \\\n",
       "0   0294-2460202            info@laxmicaterers.in   \n",
       "1   098291 20009       pannalalcaterers@gmail.com   \n",
       "2   0291-2627181         info@jodhpurcaterers.com   \n",
       "3   0294-2423634      info@shrimarwarcaterers.com   \n",
       "4   098290 57993  sharmacaterers.jaipur@gmail.com   \n",
       "\n",
       "                             Specialties                   Price Range  \n",
       "0      Vegetarian, North Indian, Chinese  Rs. 500 - Rs. 1000 per plate  \n",
       "1  Rajasthani, North Indian, Continental   Rs. 300 - Rs. 800 per plate  \n",
       "2      Rajasthani, North Indian, Chinese  Rs. 600 - Rs. 1500 per plate  \n",
       "3  Rajasthani, North Indian, Continental   Rs. 200 - Rs. 500 per plate  \n",
       "4      Rajasthani, North Indian, Chinese   Rs. 100 - Rs. 300 per plate  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a98d9e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 12.90\n"
     ]
    }
   ],
   "source": [
    "#Naive bayes for checking the accuracy\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# define the feature and target columns\n",
    "X = events[\"Specialties\"]\n",
    "y = events[\"Price Range\"]\n",
    "\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# define a pipeline to vectorize text and train a Multinomial Naive Bayes classifier\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer()),\n",
    "    (\"classifier\", MultinomialNB())\n",
    "])\n",
    "\n",
    "# fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# calculate accuracy of the model on the test set\n",
    "a = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print the accuracy score\n",
    "print(\"Accuracy on test set: {:.2f}\".format(a*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a509738a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.13\n"
     ]
    }
   ],
   "source": [
    "#Random Forest for accuracy\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# define the feature and target columns\n",
    "X = events[\"Email Address\"]\n",
    "y = events[\"Price Range\"]\n",
    "\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# define a pipeline to vectorize text and train a Random Forest Classifier\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer()),\n",
    "    (\"classifier\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# calculate accuracy of the model on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print the accuracy score\n",
    "print(\"Accuracy on test set: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80f79764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.10\n"
     ]
    }
   ],
   "source": [
    "#SVM for accuracy\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# define the feature and target columns\n",
    "X = events[\"Email Address\"]\n",
    "y = events[\"Price Range\"]\n",
    "\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# define a pipeline to vectorize text and train a SVM Classifier\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer()),\n",
    "    (\"classifier\", SVC())\n",
    "])\n",
    "\n",
    "# fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# calculate accuracy of the model on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print the accuracy score\n",
    "print(\"Accuracy on test set: {:.2f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cabebb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(events,open('events.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d5029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "692d0fd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'event' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kk/4lq_df0j7dd98flcw7vpg2kh0000gn/T/ipykernel_44119/4099457697.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Train and test the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0muser_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"New Delhi\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"300\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mrecommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent_based_filtering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommendations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kk/4lq_df0j7dd98flcw7vpg2kh0000gn/T/ipykernel_44119/4099457697.py\u001b[0m in \u001b[0;36mcontent_based_filtering\u001b[0;34m(user_events)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecommend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mtemp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Caterer Name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrecommend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Address'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Price Range'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Price Range'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'event' is not defined"
     ]
    }
   ],
   "source": [
    "# Content-Based-Filtering\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Gather data\n",
    "events = pd.read_csv('caterings1.csv')\n",
    "#url = (r\"\")\n",
    "\n",
    "\n",
    "# Define features\n",
    "features = [ 'Caterer Name','Address','Price Range','Email Address']\n",
    "\n",
    "# Preprocess data\n",
    "events = events.drop_duplicates(subset=['Email Address']) # Remove duplicates\n",
    "events = events[features].fillna('') # Fill any missing values with empty string\n",
    "\n",
    "# Vectorize features\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(events.apply(lambda x: ' '.join(x.astype(str)), axis=1))\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "# Build the model / Training the model\n",
    "def content_based_filtering(user_events):\n",
    "    # Get user's event history\n",
    "    user_vector = vectorizer.transform([' '.join(user_events)])\n",
    "    \n",
    "    # Compute similarity scores between user's history and all events\n",
    "    similarity_scores = cosine_similarity(user_vector, vectors).flatten()\n",
    "    \n",
    "    # Get top n most similar events\n",
    "    top_indices = similarity_scores.argsort()[::-1]#[:n_recommendations]\n",
    "    \n",
    "    recommend=events.iloc[top_indices]\n",
    "    \n",
    "    data = []\n",
    "    for i in recommend:\n",
    "        item = []\n",
    "        temp_df = event[event['Caterer Name'] == recommend.index[i[0]]]\n",
    "        item.extend(list(temp_df.drop_duplicates('Address')['Address'].values))\n",
    "        item.extend(list(temp_df.drop_duplicates('Price Range')['Price Range'].values))\n",
    "        item.extend(list(temp_df.drop_duplicates('Contact Number')['Contact Number'].values))\n",
    "        item.extend(list(temp_df.drop_duplicates('Email Address')['Email Address'].values))\n",
    "        item.extend(list(temp_df.drop_duplicates('Specialties')['Specialties'].values))\n",
    "\n",
    "        data.append(item)\n",
    "\n",
    "    print(data)\n",
    "    \n",
    "    # Return event recommendations\n",
    "    return recommend\n",
    "\n",
    "# Train and test the model\n",
    "user_events = [\"New Delhi\",\"300\"]\n",
    "recommendations = content_based_filtering(user_events)\n",
    "print(recommendations)\n",
    "\n",
    "\n",
    "#Integrating the frontend\n",
    "#Create a function - def input_from_frontend(para 1, 2, 3, 4):\n",
    "    #Call the function content_based_filterating\n",
    "    #Return an integer #POST\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f0180d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
